{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Overview\n",
    "**Purpose:**\n",
    "1. Generate training and testing sequences: \n",
    "2. Generate negative samples for each sequence\n",
    "3. Generate category distribution matrix for each collective POI\n",
    "4. Generate index map for reindexed POIs and Users\n",
    "\n",
    "**Input file:** \n",
    "1. Original Data: 'data_CHA.csv'\n",
    "2. Helper Function Libaray: 'Helper_Functions.py'\n",
    "\n",
    "**Output file:** \n",
    "1. Sample sets consisting POI, distance, time, type, category, negative sequence\n",
    "2. POI, user, category id mapping from old to new\n",
    "3. Collective POI's category distribution dictionary\n",
    "4. POI distance matrix \n",
    "5. Other paramters: POI max_distance and max_sequence_length\n",
    "\n",
    "**Creation Date:** 4th Nov 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "# import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import helper functions\n",
    "\n",
    "import Helper_Functions as Helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjustable parameters:\n",
    "\n",
    "1. **small_sample** *(boolean)*: Whether to use a small sample (1000 visits) for testing\n",
    "2. **augment_sample** *(boolean)*: Whether to perform sample augmentation\n",
    "3. **pad_data** *(boolean)*: Whether to perform padding on data sequence\n",
    "\n",
    "4. **min_seq_len** *(int)*: Minimum No. POIs for a valid sequence\n",
    "5. **min_seq_num** *(int)*: Minimun No. valid sequences for a valid user\n",
    "6. **neg_sample_num** *(int)*: Number of negative samples for each POI"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# setup parameters (for terminal execution)\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Settings of data processing')\n",
    "\n",
    "parser.add_argument('--small_sample',type=int,default=False,help='Whether to use a small sample (1000 visits) for testing')\n",
    "parser.add_argument('--augment_sample',type=bool,default=False,help='Whether to perform sample augmentation')\n",
    "parser.add_argument('--pad_data',type=bool,default=False,help='Whether to perform padding on data sequence')\n",
    "parser.add_argument('--min_seq_len',type=int,default=2,help='Minimum No. POIs for a valid sequence')\n",
    "parser.add_argument('--min_seq_num',type=int,default=2,help='Minimun No. valid sequences for a valid user')\n",
    "parser.add_argument('--neg_sample_num',type=int,default=5,help='Number of negative samples for each POI')\n",
    "\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup parameters (for ipython execution)\n",
    "\n",
    "small_sample = False\n",
    "augment_sample = True\n",
    "pad_data = False\n",
    "\n",
    "min_seq_len = 2\n",
    "min_seq_num = 2\n",
    "neg_sample_num = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if small_sample:  \n",
    "    data = pd.read_csv('./data_PHO.csv')[:20000] \n",
    "else: \n",
    "    data = pd.read_csv('./data_PHO.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed</th>\n",
       "      <th>Location_id</th>\n",
       "      <th>POI_id</th>\n",
       "      <th>POI_Type</th>\n",
       "      <th>Org_id</th>\n",
       "      <th>User_id</th>\n",
       "      <th>TimeStamp</th>\n",
       "      <th>Zone</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 0_y</th>\n",
       "      <th>POI_id_y</th>\n",
       "      <th>POI_Type_y</th>\n",
       "      <th>Latitude_y</th>\n",
       "      <th>Longitude_y</th>\n",
       "      <th>Category_2_y</th>\n",
       "      <th>Org_id_y</th>\n",
       "      <th>yelp_ID_y</th>\n",
       "      <th>name_y</th>\n",
       "      <th>stars_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>557</td>\n",
       "      <td>557</td>\n",
       "      <td>Independent</td>\n",
       "      <td>4b196b3af964a52000dd23e3</td>\n",
       "      <td>92745</td>\n",
       "      <td>Tue Apr 03 18:09:08 +0000 2012</td>\n",
       "      <td>-420</td>\n",
       "      <td>33.479985</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>557</td>\n",
       "      <td>Independent</td>\n",
       "      <td>33.479985</td>\n",
       "      <td>-112.077729</td>\n",
       "      <td>Sandwich Place</td>\n",
       "      <td>4b196b3af964a52000dd23e3</td>\n",
       "      <td>yUh85ZlAq_zZ9-rRlvCgcA</td>\n",
       "      <td>Sacks Sandwiches - Phoenix</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3321</td>\n",
       "      <td>3321</td>\n",
       "      <td>Independent</td>\n",
       "      <td>4a901a25f964a520021620e3</td>\n",
       "      <td>65794</td>\n",
       "      <td>Tue Apr 03 18:27:40 +0000 2012</td>\n",
       "      <td>-420</td>\n",
       "      <td>33.610450</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3321</td>\n",
       "      <td>Independent</td>\n",
       "      <td>33.610450</td>\n",
       "      <td>-112.147466</td>\n",
       "      <td>Coffee Shop</td>\n",
       "      <td>4a901a25f964a520021620e3</td>\n",
       "      <td>KY4Mg8wSgDg4UpHRB_7JFg</td>\n",
       "      <td>Starbucks</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3321</td>\n",
       "      <td>3321</td>\n",
       "      <td>Independent</td>\n",
       "      <td>4a901a25f964a520021620e3</td>\n",
       "      <td>18884</td>\n",
       "      <td>Tue Apr 03 20:26:50 +0000 2012</td>\n",
       "      <td>-420</td>\n",
       "      <td>33.610450</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3321</td>\n",
       "      <td>Independent</td>\n",
       "      <td>33.610450</td>\n",
       "      <td>-112.147466</td>\n",
       "      <td>Coffee Shop</td>\n",
       "      <td>4a901a25f964a520021620e3</td>\n",
       "      <td>KY4Mg8wSgDg4UpHRB_7JFg</td>\n",
       "      <td>Starbucks</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3321</td>\n",
       "      <td>3321</td>\n",
       "      <td>Independent</td>\n",
       "      <td>4a901a25f964a520021620e3</td>\n",
       "      <td>65794</td>\n",
       "      <td>Wed Apr 04 17:24:19 +0000 2012</td>\n",
       "      <td>-420</td>\n",
       "      <td>33.610450</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3321</td>\n",
       "      <td>Independent</td>\n",
       "      <td>33.610450</td>\n",
       "      <td>-112.147466</td>\n",
       "      <td>Coffee Shop</td>\n",
       "      <td>4a901a25f964a520021620e3</td>\n",
       "      <td>KY4Mg8wSgDg4UpHRB_7JFg</td>\n",
       "      <td>Starbucks</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3321</td>\n",
       "      <td>3321</td>\n",
       "      <td>Independent</td>\n",
       "      <td>4a901a25f964a520021620e3</td>\n",
       "      <td>18884</td>\n",
       "      <td>Sat Apr 07 19:47:10 +0000 2012</td>\n",
       "      <td>-420</td>\n",
       "      <td>33.610450</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3321</td>\n",
       "      <td>Independent</td>\n",
       "      <td>33.610450</td>\n",
       "      <td>-112.147466</td>\n",
       "      <td>Coffee Shop</td>\n",
       "      <td>4a901a25f964a520021620e3</td>\n",
       "      <td>KY4Mg8wSgDg4UpHRB_7JFg</td>\n",
       "      <td>Starbucks</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed  Location_id  POI_id     POI_Type  \\\n",
       "0           0        0          557     557  Independent   \n",
       "1           1        1         3321    3321  Independent   \n",
       "2           2        2         3321    3321  Independent   \n",
       "3           3        3         3321    3321  Independent   \n",
       "4           4        4         3321    3321  Independent   \n",
       "\n",
       "                     Org_id  User_id                       TimeStamp  Zone  \\\n",
       "0  4b196b3af964a52000dd23e3    92745  Tue Apr 03 18:09:08 +0000 2012  -420   \n",
       "1  4a901a25f964a520021620e3    65794  Tue Apr 03 18:27:40 +0000 2012  -420   \n",
       "2  4a901a25f964a520021620e3    18884  Tue Apr 03 20:26:50 +0000 2012  -420   \n",
       "3  4a901a25f964a520021620e3    65794  Wed Apr 04 17:24:19 +0000 2012  -420   \n",
       "4  4a901a25f964a520021620e3    18884  Sat Apr 07 19:47:10 +0000 2012  -420   \n",
       "\n",
       "    Latitude  ...  Unnamed: 0_y POI_id_y   POI_Type_y Latitude_y  Longitude_y  \\\n",
       "0  33.479985  ...             0      557  Independent  33.479985  -112.077729   \n",
       "1  33.610450  ...             1     3321  Independent  33.610450  -112.147466   \n",
       "2  33.610450  ...             1     3321  Independent  33.610450  -112.147466   \n",
       "3  33.610450  ...             1     3321  Independent  33.610450  -112.147466   \n",
       "4  33.610450  ...             1     3321  Independent  33.610450  -112.147466   \n",
       "\n",
       "     Category_2_y                  Org_id_y               yelp_ID_y  \\\n",
       "0  Sandwich Place  4b196b3af964a52000dd23e3  yUh85ZlAq_zZ9-rRlvCgcA   \n",
       "1     Coffee Shop  4a901a25f964a520021620e3  KY4Mg8wSgDg4UpHRB_7JFg   \n",
       "2     Coffee Shop  4a901a25f964a520021620e3  KY4Mg8wSgDg4UpHRB_7JFg   \n",
       "3     Coffee Shop  4a901a25f964a520021620e3  KY4Mg8wSgDg4UpHRB_7JFg   \n",
       "4     Coffee Shop  4a901a25f964a520021620e3  KY4Mg8wSgDg4UpHRB_7JFg   \n",
       "\n",
       "                       name_y  stars_y  \n",
       "0  Sacks Sandwiches - Phoenix      4.0  \n",
       "1                   Starbucks      3.0  \n",
       "2                   Starbucks      3.0  \n",
       "3                   Starbucks      3.0  \n",
       "4                   Starbucks      3.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed', 'Location_id', 'POI_id', 'POI_Type', 'Org_id',\n",
       "       'User_id', 'TimeStamp', 'Zone', 'Latitude', 'Longitude', 'Category_2',\n",
       "       'yelp_ID', 'name', 'stars', 'Time', 'date', 'Local_sg_time', 'L2_id',\n",
       "       'Unnamed: 0_y', 'POI_id_y', 'POI_Type_y', 'Latitude_y', 'Longitude_y',\n",
       "       'Category_2_y', 'Org_id_y', 'yelp_ID_y', 'name_y', 'stars_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Visit Sequence \n",
    "Generate valid index sequences for each valid user"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# check consecutiveness of User_id, Location_id, POI_id, L1_id, L2_id (only when full run)\n",
    "\n",
    "if not(small_sample): \n",
    "    \n",
    "    check_columns = ['User_id','Location_id','POI_id','L1_id','L2_id']\n",
    "\n",
    "    for col in check_columns:\n",
    "        Helper.check_is_consecutive(np.array(data[col]), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[                                                                        ]   0%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  Unnamed  Location_id  POI_id     POI_Type  \\\n",
      "0           0        0          557     557  Independent   \n",
      "\n",
      "                     Org_id  User_id                       TimeStamp  Zone  \\\n",
      "0  4b196b3af964a52000dd23e3    92745  Tue Apr 03 18:09:08 +0000 2012  -420   \n",
      "\n",
      "    Latitude  ...  Unnamed: 0_y POI_id_y   POI_Type_y Latitude_y  Longitude_y  \\\n",
      "0  33.479985  ...             0      557  Independent  33.479985  -112.077729   \n",
      "\n",
      "     Category_2_y                  Org_id_y               yelp_ID_y  \\\n",
      "0  Sandwich Place  4b196b3af964a52000dd23e3  yUh85ZlAq_zZ9-rRlvCgcA   \n",
      "\n",
      "                       name_y  stars_y  \n",
      "0  Sacks Sandwiches - Phoenix      4.0  \n",
      "\n",
      "[1 rows x 29 columns]\n",
      "     Unnamed: 0  Unnamed  Location_id  POI_id     POI_Type  \\\n",
      "129         129      129          417     417  Independent   \n",
      "202         202      202          561     561  Independent   \n",
      "\n",
      "                       Org_id  User_id                       TimeStamp  Zone  \\\n",
      "129  4aaebc5ff964a520146320e3    92745  Wed Apr 04 01:31:54 +0000 2012  -420   \n",
      "202  4b86ebd4f964a52003a631e3    92745  Wed Apr 04 18:32:18 +0000 2012  -420   \n",
      "\n",
      "      Latitude  ...  Unnamed: 0_y POI_id_y   POI_Type_y Latitude_y  \\\n",
      "129  33.465549  ...            62      417  Independent  33.465549   \n",
      "202  33.480042  ...           115      561  Independent  33.480042   \n",
      "\n",
      "     Longitude_y              Category_2_y                  Org_id_y  \\\n",
      "129  -112.081647  Mediterranean Restaurant  4aaebc5ff964a520146320e3   \n",
      "202  -112.081279        Mexican Restaurant  4b86ebd4f964a52003a631e3   \n",
      "\n",
      "                  yelp_ID_y                    name_y  stars_y  \n",
      "129  e880MGw6C6PJL-n3EJoY_g              Zoes Kitchen      3.5  \n",
      "202  DaVTuhzi6EgWStb2eAjNjA  Presidio Cocina Mexicana      4.5  \n",
      "\n",
      "[2 rows x 29 columns]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "201",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-5a51d7feaffa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# form visit sequences\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mvisit_sequences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_seq_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_visits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_reIndex_mapping\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHelper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_seq_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_seq_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvisit_sequences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'no qualified sequence after filtering!'\u001b[0m \u001b[1;31m# check if output sequence is empty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Model Implementation\\Helper_Functions.py\u001b[0m in \u001b[0;36mgenerate_sequence\u001b[1;34m(input_data, min_seq_len, min_seq_num)\u001b[0m\n\u001b[0;32m    108\u001b[0m                         \u001b[0msingle_date_visit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_date_group\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msingle_date_visit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m                         \u001b[0msingle_sequence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_remove_consecutive_visit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msingle_date_visit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbar\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# reovme consecutive visits in each sequence\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msingle_sequence\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mmin_seq_len\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# add previous sequence (if valid) to user_sequences\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Model Implementation\\Helper_Functions.py\u001b[0m in \u001b[0;36m_remove_consecutive_visit\u001b[1;34m(visit_record, bar)\u001b[0m\n\u001b[0;32m     52\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mvisit_record\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# skip first row\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m                         \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m                 \u001b[1;32melif\u001b[0m \u001b[0mvisit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'POI_id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mvisit_record\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'POI_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# only accept non-repeated visit\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m                         \u001b[0mclean_sequence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wuziq\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    866\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 868\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wuziq\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   4372\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4373\u001b[0m             return self._engine.get_value(s, k,\n\u001b[1;32m-> 4374\u001b[1;33m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[0;32m   4375\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4376\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 201"
     ]
    }
   ],
   "source": [
    "# form visit sequences \n",
    "\n",
    "visit_sequences, max_seq_len, valid_visits, user_reIndex_mapping = Helper.generate_sequence(data, min_seq_len, min_seq_num)\n",
    "\n",
    "assert bool(visit_sequences), 'no qualified sequence after filtering!' # check if output sequence is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Helper.peep_dictionary(visit_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(valid_visits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_reIndex_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment sequences (optional)\n",
    "\n",
    "if augment_sample:\n",
    "#     visit_sequences = Helper.aug_sequence(visit_sequences, min_len=3)\n",
    "    visit_sequences, ground_truth_dict = Helper.aug_sequence(visit_sequences, min_len=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Helper.peep_dictionary(visit_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Helper.peep_dictionary(ground_truth_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad sequences (optional)\n",
    "\n",
    "if pad_data:\n",
    "    \n",
    "    visit_sequences = Helper.pad_sequence(visit_sequences, max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Helper.peep_dictionary(visit_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Input Sequences\n",
    "Five input sequences paralleled with the Visit Sequence are prepared:\n",
    "1. POI sequence\n",
    "2. Distance sequence\n",
    "3. Time sequence\n",
    "4. Type sequence\n",
    "5. Category sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate POI sequence\n",
    "\n",
    "POI_sequences, POI_reIndex_mapping = Helper.generate_POI_sequences(data, visit_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "POI_sequences[0] # POI_sequence for first user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "POI_reIndex_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate distance sequence\n",
    "\n",
    "dist_sequences, max_dist = Helper.generate_dist_sequences(data, visit_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dist_sequences[0] # dist_sequence for first user # can perform analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dist # maximum distance between two consecutive visits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate time sequence\n",
    "\n",
    "time_sequences = Helper.generate_time_sequences(data, visit_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "time_sequences[0] # time_sequence for first user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generage Type sequence\n",
    "\n",
    "type_sequences = Helper.generate_type_sequence(data, visit_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type_sequences[0] # type_sequence for first user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate category sequence\n",
    "\n",
    "cat_sequences, cat_reIndex_mapping = Helper.generate_cat_sequences(data, visit_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cat_sequences[0] # cat_sequence for first user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat_reIndex_mapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate ground truth for each sequence\n",
    "\n",
    "ground_truth_sequences = Helper.generate_ground_truth_sequences(data, ground_truth_dict, POI_reIndex_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate specific poi ground truth for each sequence\n",
    "\n",
    "specific_poi_sequences = Helper.generate_specific_poi_sequences(data, ground_truth_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_poi_sequences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extra Data Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collective POI's category distribution\n",
    "\n",
    "For each collective POI, count the number stores belongs to each category it has.\n",
    "The distribution is recorded in a 2-layer dictionary of form:\n",
    "\n",
    "{ POI_id (new id) : { category_id (new id): store count (int)} }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# generate collective POI's category distribution\n",
    "\n",
    "poi_cat_distrib = Helper.generate_cat_distrib(data, valid_visits, POI_reIndex_mapping, cat_reIndex_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Helper.peep_dictionary(poi_cat_distrib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "poi_cat_distrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_visit_data = data[data.index.isin(valid_visits)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Samples for Each Sequence\n",
    "\n",
    "For each user's each sequence, generate 'neg_sample_num' number of negative POIs\n",
    "\n",
    "Negative POIs statisfy following criteria:\n",
    "\n",
    "1. The POI does not appear in the true sequence \n",
    "\n",
    "2. The distance between:\n",
    "    *a) negative POI and true destination* and \n",
    "    *b) true second last POI and true destination*\n",
    "   should be as close as possible\n",
    "   \n",
    "The output neg_sequences should be a 3d array of shape [user, seq, neg_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store distance between each valid POI (time consuming)\n",
    "    \n",
    "dist_mat = Helper.generate_POI_dist_mat(data, POI_reIndex_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# generate negative samples \n",
    "\n",
    "neg_sequences = Helper.generate_neg_sequences(POI_sequences, dist_mat, neg_sample_num, data, POI_reIndex_mapping, cat_reIndex_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_sequences[0] # negative samples for each sequence of 1st user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat_reIndex_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate poi_cat_specific_poi_dict mapping\n",
    "\n",
    "grouped = data.groupby(['POI_id', 'L2_id'])['Location_id'].unique().apply(list)\n",
    "\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate poi_cat_specific_poi_dict\n",
    "\n",
    "poi_cat_specific_poi_dict = {}\n",
    "\n",
    "prev_poi = grouped.index[0][0]\n",
    "\n",
    "cat_specific_poi_dict = {}\n",
    "\n",
    "cat_specific_poi_dict[grouped.index[0][1]] = grouped[grouped.index[0]]\n",
    "\n",
    "for index in grouped.index:\n",
    "\n",
    "    if index[0] not in poi_cat_specific_poi_dict.keys():  \n",
    "        \n",
    "        poi_cat_specific_poi_dict[prev_poi] = cat_specific_poi_dict\n",
    "        \n",
    "        cat_specific_poi_dict = {}\n",
    "        \n",
    "        prev_poi = index[0]\n",
    "        \n",
    "        poi_cat_specific_poi_dict[index[0]] = {}\n",
    "        \n",
    "    cat_specific_poi_dict[index[1]] = grouped[index]\n",
    "    \n",
    "poi_cat_specific_poi_dict[prev_poi] = cat_specific_poi_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_cat_specific_poi_dict[317]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Form Sample Sets\n",
    "\n",
    "Concatenate five sequences to form a sample, which is a tuple consists of: (POI_seq, dist_seq, time_seq, type_seq, cat_seq, neg_samplw)\n",
    "\n",
    "Organise samples according to users in a dictionary of form:\n",
    "\n",
    "{ User_id (new id) : sample sets } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# form sample set for each user\n",
    "\n",
    "sample_sets = Helper.form_sample_sets(POI_sequences, dist_sequences, time_sequences, type_sequences, cat_sequences, ground_truth_sequences, specific_poi_sequences, neg_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Helper.peep_dictionary(sample_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Output Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set output directory\n",
    "\n",
    "dir = './np_save_PHO/'\n",
    "if small_sample:\n",
    "    dir = './test_np_save_PHO/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directory if not exists\n",
    "\n",
    "if not os.path.exists(dir):\n",
    "    os.makedirs(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save concatenated samples\n",
    "\n",
    "Helper.save_dict(sample_sets, dir + 'sample_sets.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save id mappings\n",
    "\n",
    "np.save(dir + 'POI_reIndex_mapping.npy', POI_reIndex_mapping)\n",
    "np.save(dir + 'user_reIndex_mapping.npy', user_reIndex_mapping)\n",
    "np.save(dir + 'cat_reIndex_mapping.npy', cat_reIndex_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save collective POI's category distribution dictionary\n",
    "\n",
    "Helper.save_dict(poi_cat_distrib, dir + 'poi_cat_distrib.pkl')\n",
    "Helper.save_dict(poi_cat_specific_poi_dict, dir + 'poi_cat_specific_poi_dict.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save POI distance matrix \n",
    "\n",
    "np.save(dir + 'dist_mat.npy', dist_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save other relavant parameters\n",
    "\n",
    "np.save(dir + 'max_dist.npy', max_dist) # max distance (for distance embedding)\n",
    "np.save(dir + 'max_seq_len.npy', max_seq_len) # max sequence length (for input size)\n",
    "np.save(dir + 'neg_sample_num.npy', neg_sample_num) # number of negative samples (for negative input size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
